{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Compact architectures\n## Audio Classification with the NBAC dataset\n\nThis notebook performs audio classification on audio fragments of 5 seconds long","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"# IMPORT ALL LIBRARIES\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport pandas as pd\nimport random\nimport seaborn as sns\n\nimport librosa\nimport librosa.display\n\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\n\nfrom tensorflow.keras.layers import Layer, Conv2D, MaxPooling2D, Flatten, Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.applications import MobileNet\nfrom tensorflow.keras.optimizers import Adam\n\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.models import load_model","metadata":{"execution":{"iopub.status.busy":"2023-07-20T11:14:27.181808Z","iopub.execute_input":"2023-07-20T11:14:27.183278Z","iopub.status.idle":"2023-07-20T11:14:33.084268Z","shell.execute_reply.started":"2023-07-20T11:14:27.183249Z","shell.execute_reply":"2023-07-20T11:14:33.083089Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Load the data","metadata":{}},{"cell_type":"code","source":"# Set sample rate to work with at 8000\n\nSR = 16000","metadata":{"execution":{"iopub.status.busy":"2023-07-20T11:14:33.086172Z","iopub.execute_input":"2023-07-20T11:14:33.086978Z","iopub.status.idle":"2023-07-20T11:14:33.093240Z","shell.execute_reply.started":"2023-07-20T11:14:33.086937Z","shell.execute_reply":"2023-07-20T11:14:33.090688Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"info = pd.read_csv('/kaggle/input/esc50dataset/ESC-50-master/ESC-50-master/meta/esc50.csv')","metadata":{"execution":{"iopub.status.busy":"2023-07-20T11:14:33.094681Z","iopub.execute_input":"2023-07-20T11:14:33.096957Z","iopub.status.idle":"2023-07-20T11:14:33.119636Z","shell.execute_reply.started":"2023-07-20T11:14:33.096929Z","shell.execute_reply":"2023-07-20T11:14:33.118611Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"info_list = list(info['category'].unique())\n\nlabels = {}\n\nfor i, label in enumerate(info_list):\n        labels[label] = i\n\nNUM_CLASSES = len(labels)","metadata":{"execution":{"iopub.status.busy":"2023-07-20T11:14:33.123354Z","iopub.execute_input":"2023-07-20T11:14:33.123627Z","iopub.status.idle":"2023-07-20T11:14:33.130068Z","shell.execute_reply.started":"2023-07-20T11:14:33.123602Z","shell.execute_reply":"2023-07-20T11:14:33.128956Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Create a new empty dictionary\nreversed_labels = {}\n\n# Iterate through the key-value pairs in the dictionary\nfor key, value in labels.items():\n  # Add the key-value pair to the new dictionary in the reverse order\n  reversed_labels[value] = key","metadata":{"execution":{"iopub.status.busy":"2023-07-20T11:14:33.132072Z","iopub.execute_input":"2023-07-20T11:14:33.132477Z","iopub.status.idle":"2023-07-20T11:14:33.140441Z","shell.execute_reply.started":"2023-07-20T11:14:33.132422Z","shell.execute_reply":"2023-07-20T11:14:33.139292Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"esc50_files = list(info['filename'])","metadata":{"execution":{"iopub.status.busy":"2023-07-20T11:14:33.143688Z","iopub.execute_input":"2023-07-20T11:14:33.143982Z","iopub.status.idle":"2023-07-20T11:14:33.152500Z","shell.execute_reply.started":"2023-07-20T11:14:33.143948Z","shell.execute_reply":"2023-07-20T11:14:33.151463Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### Load the wav files","metadata":{}},{"cell_type":"code","source":"ESC50_FOLDER = '/kaggle/input/esc50dataset/ESC-50-master/ESC-50-master/audio'","metadata":{"execution":{"iopub.status.busy":"2023-07-20T11:14:33.155671Z","iopub.execute_input":"2023-07-20T11:14:33.156609Z","iopub.status.idle":"2023-07-20T11:14:33.163502Z","shell.execute_reply.started":"2023-07-20T11:14:33.156575Z","shell.execute_reply":"2023-07-20T11:14:33.162401Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def wav_data_loader(files, normalization=True):\n    \n    all_fragments = []\n    \n    for file in files:\n        \n        # Load the audio file\n        \n        AUDIO_FILE = os.path.join(ESC50_FOLDER, file)\n        \n        sample, sample_rate = librosa.load(AUDIO_FILE, sr=SR)\n        \n        if normalization==True:\n            \n            # Normalize the waveform\n            sample = librosa.util.normalize(sample)\n        \n        cat = info[info['filename'] == file]['category'].iloc[0]\n        \n        sample = (sample, labels[cat])    \n    \n        all_fragments.append(sample)\n    \n    return all_fragments","metadata":{"execution":{"iopub.status.busy":"2023-07-20T11:14:33.164926Z","iopub.execute_input":"2023-07-20T11:14:33.165333Z","iopub.status.idle":"2023-07-20T11:14:33.175921Z","shell.execute_reply.started":"2023-07-20T11:14:33.165300Z","shell.execute_reply":"2023-07-20T11:14:33.174871Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"%%time\nesc50_wav_dataset = wav_data_loader(esc50_files, normalization=False)","metadata":{"execution":{"iopub.status.busy":"2023-07-20T11:14:33.177442Z","iopub.execute_input":"2023-07-20T11:14:33.177824Z","iopub.status.idle":"2023-07-20T11:15:00.721005Z","shell.execute_reply.started":"2023-07-20T11:14:33.177793Z","shell.execute_reply":"2023-07-20T11:15:00.719835Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"CPU times: user 12.2 s, sys: 1.32 s, total: 13.6 s\nWall time: 27.5 s\n","output_type":"stream"}]},{"cell_type":"code","source":"len(esc50_wav_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-07-20T11:15:00.722952Z","iopub.execute_input":"2023-07-20T11:15:00.723852Z","iopub.status.idle":"2023-07-20T11:15:00.732533Z","shell.execute_reply.started":"2023-07-20T11:15:00.723808Z","shell.execute_reply":"2023-07-20T11:15:00.731106Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"2000"},"metadata":{}}]},{"cell_type":"markdown","source":"## Train-test split\n\nCreating a first train-test split in the original dataset will be useful for correct data augmentation and pre-processing techniques.","metadata":{}},{"cell_type":"code","source":"X = [wav[0] for wav in esc50_wav_dataset]\ny = [wav[1] for wav in esc50_wav_dataset]\n\nX_train_wav, X_test_wav, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\nX_train_wav, X_val_wav, y_train, y_val = train_test_split(X_train_wav, y_train, test_size=0.2, stratify=y_train, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-07-20T11:15:00.734621Z","iopub.execute_input":"2023-07-20T11:15:00.735073Z","iopub.status.idle":"2023-07-20T11:15:00.755327Z","shell.execute_reply.started":"2023-07-20T11:15:00.735032Z","shell.execute_reply":"2023-07-20T11:15:00.754179Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Waveform augmentation","metadata":{}},{"cell_type":"code","source":"## Noise addition\n\ndef add_noise(wav_data, noise_factor):\n\n    # Generate noise signal with the same shape as input waveform\n    noise = np.random.normal(0, 1, len(wav_data))\n\n    # Scale noise signal with the permissible noise factor value\n    noise *= noise_factor\n\n    # Add noise signal to input waveform\n    augmented_wav_data = wav_data + noise\n\n    # Normalize the augmented waveform data\n    augmented_wav_data = librosa.util.normalize(augmented_wav_data)\n\n    return augmented_wav_data\n\ndef time_shift(audio, p):\n    \"\"\"\n    Shift audio to the left or right by a random amount.\n    \"\"\"\n    # Calculate the length of the audio array\n    length = audio.shape[0]\n\n    # Calculate the maximum number of samples to shift\n    max_shift = int(length * p)\n\n    # Generate a random shift value\n    shift = random.randint(-max_shift, max_shift)\n\n    # Create an empty array with the same shape as the audio array\n    shifted_audio = np.zeros_like(audio)\n\n    # Shift the audio by the specified number of samples\n    if shift > 0:\n      # Shift to the right\n        shifted_audio[shift:] = audio[:length-shift]\n    else:\n        # Shift to the left\n        shifted_audio[:length+shift] = audio[-shift:]\n    \n    if np.sum(shifted_audio) == 0:\n        #revert the process if all information was erased\n        shifted_audio = audio     \n\n    return shifted_audio\n\ndef time_stretching(audio,factor):\n    \n    wav_time_stch = librosa.effects.time_stretch(audio,rate=factor)\n    \n    return wav_time_stch[:SR*5]","metadata":{"execution":{"iopub.status.busy":"2023-07-20T11:15:00.756948Z","iopub.execute_input":"2023-07-20T11:15:00.757716Z","iopub.status.idle":"2023-07-20T11:15:00.770209Z","shell.execute_reply.started":"2023-07-20T11:15:00.757681Z","shell.execute_reply":"2023-07-20T11:15:00.768793Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"len(X_train_wav)","metadata":{"execution":{"iopub.status.busy":"2023-07-20T11:15:00.774547Z","iopub.execute_input":"2023-07-20T11:15:00.774968Z","iopub.status.idle":"2023-07-20T11:15:00.785649Z","shell.execute_reply.started":"2023-07-20T11:15:00.774923Z","shell.execute_reply":"2023-07-20T11:15:00.784509Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"1120"},"metadata":{}}]},{"cell_type":"code","source":"%%time\n''' EXUCUTE THIS CELL TO APPLY DATA AUGMENTATION\nLots of memory required this step could be optimized'''\n\ndef augment_wavs(wav_dataset, y):\n    \n    y = list(y)\n    \n    wav_dataset_augmented = []\n\n    for wav in wav_dataset:\n        # Create a copy of the original wav to prevent unwanted side effects\n        temp_wav = wav.copy()\n        temp_wav = add_noise(temp_wav, 0.025) # We want to use values between 0.005 and 0.04\n        temp_wav = time_shift(temp_wav, 0.3)  # We want to use a max shift of 30%\n        temp_wav = time_stretching(temp_wav, 0.85)\n\n        wav_dataset_augmented.append(temp_wav)\n\n    # Add original wavs to augmented list\n    wav_dataset_augmented.extend(wav_dataset)\n    \n    y = y + y #each spec is being appended at the bottom of the list\n\n    return wav_dataset_augmented, y","metadata":{"execution":{"iopub.status.busy":"2023-07-20T11:15:00.787227Z","iopub.execute_input":"2023-07-20T11:15:00.788068Z","iopub.status.idle":"2023-07-20T11:15:00.798335Z","shell.execute_reply.started":"2023-07-20T11:15:00.787965Z","shell.execute_reply":"2023-07-20T11:15:00.797025Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"CPU times: user 5 µs, sys: 0 ns, total: 5 µs\nWall time: 9.54 µs\n","output_type":"stream"}]},{"cell_type":"code","source":"#X_train_wav, y_train = augment_wavs(X_train_wav, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-07-20T11:15:00.800201Z","iopub.execute_input":"2023-07-20T11:15:00.800561Z","iopub.status.idle":"2023-07-20T11:15:00.812269Z","shell.execute_reply.started":"2023-07-20T11:15:00.800528Z","shell.execute_reply":"2023-07-20T11:15:00.811341Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"len(X_train_wav)","metadata":{"execution":{"iopub.status.busy":"2023-07-20T11:15:00.814767Z","iopub.execute_input":"2023-07-20T11:15:00.815699Z","iopub.status.idle":"2023-07-20T11:15:00.825465Z","shell.execute_reply.started":"2023-07-20T11:15:00.815623Z","shell.execute_reply":"2023-07-20T11:15:00.824518Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"1120"},"metadata":{}}]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"markdown","source":"## Transfer learning with Imagenet","metadata":{}},{"cell_type":"code","source":"class LLF(Layer):\n    def __init__(self, sample_rate, frame_length, frame_step, num_mel_bins=64, lower_freq=125, upper_freq=7500, log_offset=0.001, **kwargs):\n        super(LLF, self).__init__(**kwargs)\n        self.sample_rate = sample_rate\n        self.frame_length = frame_length\n        self.frame_step = frame_step\n        self.num_mel_bins = num_mel_bins\n        self.lower_freq = lower_freq\n        self.upper_freq = upper_freq\n        self.log_offset = log_offset\n\n    def call(self, inputs):\n        \n        # Convert numpy array to Tensor and normalize based on its actual max and min values\n        wav = tf.cast(inputs, tf.float32)\n        audio_tensor = (wav - tf.math.reduce_min(wav)) / (tf.math.reduce_max(wav) - tf.math.reduce_min(wav)) * 2 - 1\n        \n        # Compute the Short-Time Fourier Transform (STFT)\n        stft = tf.signal.stft(wav, self.frame_length, self.frame_step, window_fn=tf.signal.hann_window)\n\n        # Compute the spectrogram\n        spectrogram = tf.abs(stft)\n\n        # Compute the mel-spectrogram\n        num_spectrogram_bins = stft.shape[-1]\n        linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n            self.num_mel_bins, num_spectrogram_bins, self.sample_rate, self.lower_freq, self.upper_freq)\n        mel_spectrogram = tf.tensordot(spectrogram, linear_to_mel_weight_matrix, 1)\n        mel_spectrogram.set_shape(spectrogram.shape[:-1].concatenate(linear_to_mel_weight_matrix.shape[-1:]))\n\n        # Compute the log mel-spectrogram\n        log_mel_spectrogram = tf.math.log(mel_spectrogram + self.log_offset)\n\n        # Add a channel dimension\n        log_mel_spectrogram = tf.expand_dims(log_mel_spectrogram, -1)\n\n        return log_mel_spectrogram\n\nsample_rate = SR  # Adjust as necessary\nwindow_size_ms = 25\nwindow_hop_ms = 10\nframe_length = sample_rate * window_size_ms // 1000\nframe_step = sample_rate * window_hop_ms // 1000\nAUDIO_LENGTH = 5\n\nclass HLFBlock(tf.keras.layers.Layer):\n    def __init__(self, **kwargs):\n        super(HLFBlock, self).__init__(**kwargs)\n        self.seq = Sequential([\n            tf.keras.layers.SeparableConv2D(32, 3, strides=2, padding='same', activation='relu'),\n            tf.keras.layers.BatchNormalization(),\n            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n            tf.keras.layers.SeparableConv2D(64, 3, padding='same', activation='relu'),\n            tf.keras.layers.BatchNormalization(),\n            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n            tf.keras.layers.SeparableConv2D(128, 3, padding='same', activation='relu'),\n            tf.keras.layers.BatchNormalization(),\n            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n        ])\n\n    def call(self, inputs):\n        return self.seq(inputs)\n\nclass EmbeddingsBlock(tf.keras.layers.Layer):\n    def __init__(self, **kwargs):\n        super(EmbeddingsBlock, self).__init__(**kwargs)\n        self.seq = Sequential([\n            tf.keras.layers.Conv2D(256, 1, padding='same', activation='relu'),\n            tf.keras.layers.Dropout(0.2),\n            tf.keras.layers.GlobalAveragePooling2D(),\n        ])\n\n    def call(self, inputs):\n        return self.seq(inputs)\n    \nHLF = HLFBlock(name='HLF')\nEmbeddings = EmbeddingsBlock(name='Embeddings')\n\n# Define the model\nmodel = Sequential([\n    LLF(sample_rate, frame_length, frame_step, input_shape=(AUDIO_LENGTH*SR,)),\n    HLF,\n    Embeddings,\n    tf.keras.layers.Dense(NUM_CLASSES),\n    tf.keras.layers.Activation('softmax')  # The activation should be softmax for multi-class classification\n])\n\n# Compile the model\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2023-07-20T11:15:00.828865Z","iopub.execute_input":"2023-07-20T11:15:00.829162Z","iopub.status.idle":"2023-07-20T11:15:04.264818Z","shell.execute_reply.started":"2023-07-20T11:15:00.829107Z","shell.execute_reply":"2023-07-20T11:15:04.263824Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def create_subsets(X, y, num_samples):\n    X = np.array(X)\n    y = np.array(y)\n    classes = np.unique(y)\n    X_subsets = []\n    y_subsets = []\n    for cls in classes:\n        idx = np.where(y == cls)[0]\n        if len(idx) > num_samples:\n            idx = np.random.choice(idx, num_samples, replace=False)\n        X_subsets.append(X[idx])\n        y_subsets.append(y[idx])\n    X_subset = np.concatenate(X_subsets)\n    y_subset = np.concatenate(y_subsets)\n    X_subset, y_subset = augment_wavs(X_subset, y_subset)\n    return X_subset, y_subset\n\ntest_accuracies = []\nsample_sizes = [22, 25, 28] # INSERT SAMPLE SIZES TO BE TESTED HERE!\n\nfor size in sample_sizes:\n    print(f'Evaluating model trained with {size} samples per class...')\n    # Define the model\n    model = Sequential([\n        LLF(sample_rate, frame_length, frame_step, input_shape=(AUDIO_LENGTH*SR,)),\n        HLF,\n        Embeddings,\n        tf.keras.layers.Dense(NUM_CLASSES),\n        tf.keras.layers.Activation('softmax')  # The activation should be softmax for multi-class classification\n    ])\n    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\n    # Get subset of data and retrain\n    X_train_subset, y_train_subset = create_subsets(X_train_wav, y_train, size)\n    model.fit(\n        np.array(X_train_subset),\n        np.array(y_train_subset),\n        epochs=50,\n        batch_size=32,\n        validation_data=(np.array(X_val_wav), np.array(y_val)),\n        verbose=0  # we don't need epoch-by-epoch output this time\n    )\n\n    # evaluate on the test set\n    test_loss, test_acc = model.evaluate(np.array(X_test_wav), np.array(y_test), verbose=0)\n    test_accuracies.append(test_acc)\n\n# plot test accuracy by training set size\nplt.figure(figsize=(10, 6))\nplt.plot(sample_sizes, test_accuracies, marker='o')\nplt.title('Test accuracy by training set size')\nplt.xlabel('Number of samples per class in training set')\nplt.ylabel('Test accuracy')\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-07-20T11:23:32.334328Z","iopub.execute_input":"2023-07-20T11:23:32.334770Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Evaluating model trained with 22 samples per class...\n","output_type":"stream"},{"name":"stderr","text":"2023-07-20 11:24:45.936169: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_7/Embeddings/sequential_1/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n","output_type":"stream"},{"name":"stdout","text":"Evaluating model trained with 25 samples per class...\n","output_type":"stream"}]}]}